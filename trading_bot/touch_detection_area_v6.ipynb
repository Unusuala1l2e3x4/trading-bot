{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Importing the modules themselves for reloading\n",
    "import trading_bot.TradePosition\n",
    "import trading_bot.TouchArea\n",
    "import trading_bot.TradingStrategy\n",
    "import trading_bot.TouchDetection\n",
    "import trading_bot.TouchDetectionParameters\n",
    "import trading_bot.MultiSymbolDataRetrieval\n",
    "import trading_bot.TypedBarData\n",
    "import trading_bot.VolumeProfile\n",
    "\n",
    "# Reloading the modules to apply any changes\n",
    "import importlib\n",
    "importlib.reload(trading_bot.TradePosition)\n",
    "importlib.reload(trading_bot.TouchArea)\n",
    "importlib.reload(trading_bot.TradingStrategy)\n",
    "importlib.reload(trading_bot.TouchDetection)\n",
    "importlib.reload(trading_bot.TouchDetectionParameters)\n",
    "importlib.reload(trading_bot.MultiSymbolDataRetrieval)\n",
    "importlib.reload(trading_bot.TypedBarData)\n",
    "importlib.reload(trading_bot.VolumeProfile)\n",
    "\n",
    "from trading_bot.TradePosition import TradePosition, csv_to_trade_positions\n",
    "from trading_bot.TradePositionPlotting import plot_cumulative_pl_and_price\n",
    "from trading_bot.TouchArea import TouchArea\n",
    "from trading_bot.TradingStrategy import StrategyParameters, TouchDetectionAreas, TradingStrategy \n",
    "\n",
    "from trading_bot.TouchDetection import calculate_touch_detection_area, plot_touch_detection_areas\n",
    "from trading_bot.TouchDetectionParameters import BacktestTouchDetectionParameters, np_median, np_mean, get_latest_value\n",
    "from trading_bot.MultiSymbolDataRetrieval import fill_missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbol = \"NVDA\" # good\n",
    "# symbol = \"MSFT\" # bad\n",
    "# symbol = \"META\" # bad\n",
    "# symbol = \"AAPL\" # mid\n",
    "# symbol = \"TJX\"\n",
    "# symbol = \"JNJ\"\n",
    "# symbol = \"AMZN\" # mid\n",
    "# symbol = \"AZN\"\n",
    "# symbol = \"TSLA\" # good\n",
    "# symbol = \"TJX\"\n",
    "# symbol = \"GOOGL\" # mid\n",
    "\n",
    "# symbol = 'MSTR' # bad\n",
    "symbol = 'MARA' # good\n",
    "# symbol = 'INTC' # bad\n",
    "# symbol = 'GOOG' # bad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2022-01-12 00:00:00\"\n",
    "end_date =   \"2022-01-13 00:00:00\"\n",
    "\n",
    "# start_date = \"2022-01-01 00:00:00\"\n",
    "# end_date =   \"2022-02-01 00:00:00\"\n",
    "\n",
    "start_date = \"2024-01-01 00:00:00\"\n",
    "# end_date =   \"2024-08-17 00:00:00\"\n",
    "end_date =   \"2024-09-27 00:00:00\"\n",
    "\n",
    "# start_date = \"2017-01-01 00:00:00\"\n",
    "# end_date =   \"2018-01-01 00:00:00\"\n",
    "\n",
    "start_date = \"2024-07-01 00:00:00\"\n",
    "end_date =   \"2024-08-01 00:00:00\"\n",
    "\n",
    "# start_date = \"2024-08-01 00:00:00\"\n",
    "# end_date =   \"2024-09-01 00:00:00\"\n",
    "\n",
    "# start_date = \"2024-09-01 00:00:00\"\n",
    "# end_date =   \"2024-10-01 00:00:00\"\n",
    "\n",
    "# start_date = \"2024-10-01 00:00:00\"\n",
    "# end_date =   \"2024-11-01 00:00:00\"\n",
    "\n",
    "# start_date = \"2024-11-01 00:00:00\"\n",
    "# end_date =   \"2024-12-01 00:00:00\"\n",
    "\n",
    "# start_date = \"2024-12-01 00:00:00\"\n",
    "# end_date =   \"2025-01-01 00:00:00\"\n",
    "\n",
    "start_date = \"2025-01-01 00:00:00\"\n",
    "end_date =   \"2025-02-01 00:00:00\"\n",
    "\n",
    "# start_date = \"2024-09-04 00:00:00\"\n",
    "# end_date =   \"2024-09-05 00:00:00\"\n",
    "\n",
    "# start_date = \"2024-11-22 00:00:00\"\n",
    "# end_date =   \"2024-11-23 00:00:00\"\n",
    "\n",
    "# Usage example:\n",
    "touch_detection_params = BacktestTouchDetectionParameters(\n",
    "    symbol=symbol,\n",
    "    client_type='stock',\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    # atr_period=15,\n",
    "    # level1_period=15,\n",
    "    # multiplier=1.4,\n",
    "    min_touches=3,\n",
    "    start_time='9:30',\n",
    "    end_time='15:55',\n",
    "    # end_time='11:20',\n",
    "    # use_median=True,\n",
    "    # touch_area_width_agg=get_latest_value,\n",
    "    \n",
    "    # ema_span=12,\n",
    "    # price_ema_span=26,\n",
    "    \n",
    "    export_bars_path=f'bars/bars_{symbol.replace('/','-')}_{start_date.split()[0]}_{end_date.split()[0]}.csv',\n",
    "    export_quotes_path=f'quotes/quotes_{symbol.replace('/','-')}_{start_date.split()[0]}_{end_date.split()[0]}.csv'\n",
    ")\n",
    "\n",
    "touch_detection_areas = calculate_touch_detection_area(touch_detection_params)\n",
    "\n",
    "# touch_detection_areas = calculate_touch_detection_area(symbol, start_date, end_date, atr_period=15, level1_period=15, multiplier=1.4, min_touches=3, start_time=None, end_time='15:55', \\\n",
    "#     use_median=True, touch_area_width_agg=np_median,  export_bars_path=f'bars_{symbol.replace('/','-')}_{start_date.split()[0]}_{end_date.split()[0]}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = touch_detection_areas.quotes.reset_index()\n",
    "# temp['minute'] = temp.timestamp.apply(lambda x: pd.Timestamp(x).replace(second=0, microsecond=0))\n",
    "# temp.groupby('minute').count()['symbol'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.groupby('minute').count()['symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sorted_quote_changes(df):\n",
    "    \"\"\"\n",
    "    Calculate and sort quote changes for each minute.\n",
    "    \n",
    "    :param df: DataFrame with (symbol, timestamp) multi-index and bid_price, ask_price columns\n",
    "    :return: DataFrame with sorted quote changes\n",
    "    \"\"\"\n",
    "    # Reset the index to make timestamp a column\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # Convert timestamp to datetime if it's not already\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    # Create a minute column\n",
    "    df['minute'] = df['timestamp'].dt.floor('min')\n",
    "\n",
    "    # Group by symbol and minute, then calculate the changes\n",
    "    grouped = df.groupby(['symbol', 'minute'])\n",
    "    changes = grouped.apply(lambda x: pd.Series({\n",
    "        'bid_change': x['bid_price'].diff().iloc[-1] if len(x) > 1 else 0,\n",
    "        'ask_change': x['ask_price'].diff().iloc[-1] if len(x) > 1 else 0,\n",
    "        'timestamp': x['timestamp'].iloc[0]  # Keep the timestamp of the first quote in the minute\n",
    "    }))\n",
    "\n",
    "    # Reset the index to make symbol and minute columns\n",
    "    changes = changes.reset_index()\n",
    "\n",
    "    # Sort by bid_change and ask_change in descending order\n",
    "    changes_sorted = changes.sort_values(['bid_change', 'ask_change'], ascending=[False, False])\n",
    "\n",
    "    return changes_sorted\n",
    "\n",
    "# Example usage:\n",
    "# sorted_changes = calculate_sorted_quote_changes(touch_detection_areas.quotes)\n",
    "# sorted_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# times = touch_detection_areas.bars.index.get_level_values('timestamp').time\n",
    "# print(touch_detection_areas.bars.loc[(times >= time(9,30)) & (times <= time(16,0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(touch_detection_areas.quotes_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(touch_detection_areas.quotes_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_quote_changes_histogram(sorted_changes, num_bins=50):\n",
    "    \"\"\"\n",
    "    Create histograms of bid and ask price changes.\n",
    "    \n",
    "    :param sorted_changes: DataFrame returned by calculate_sorted_quote_changes function\n",
    "    :param num_bins: Number of bins for the histogram (default: 50)\n",
    "    \"\"\"\n",
    "    # Create a figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12))\n",
    "    \n",
    "    # Plot histogram of bid changes\n",
    "    ax1.hist(sorted_changes['bid_change'], bins=num_bins, edgecolor='black')\n",
    "    ax1.set_title('Histogram of Bid Price Changes')\n",
    "    ax1.set_xlabel('Bid Price Change')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    \n",
    "    # Plot histogram of ask changes\n",
    "    ax2.hist(sorted_changes['ask_change'], bins=num_bins, edgecolor='black')\n",
    "    ax2.set_title('Histogram of Ask Price Changes')\n",
    "    ax2.set_xlabel('Ask Price Change')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    \n",
    "    # Adjust layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "# plot_quote_changes_histogram(sorted_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_changes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (touch_detection_areas.bars[touch_detection_areas.mask]['avg_volume_2'] == touch_detection_areas.bars[touch_detection_areas.mask]['avg_volume_3']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "touch_detection_areas.bars[touch_detection_areas.mask][['volume']+[a for a in touch_detection_areas.bars.columns if a.startswith('avg_volume')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(touch_detection_areas.bars[touch_detection_areas.mask].columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# touch_detection_areas.bars[touch_detection_areas.mask].reset_index().to_csv('asdf2.csv',index=False)\n",
    "# touch_detection_areas.bars.reset_index().to_csv('asdfasdf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = touch_detection_areas.bars[touch_detection_areas.mask]['trade_count'].astype(float).describe()\n",
    "# b = touch_detection_areas.bars[touch_detection_areas.mask]['volume'].astype(float).describe()\n",
    "# c = touch_detection_areas.bars[touch_detection_areas.mask]['shares_per_trade'].astype(float).describe()\n",
    "# pd.concat([a,b,c],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # zoom_start_date = start_date\n",
    "# # zoom_end_date = end_date\n",
    "# zoom_start_date = \"2024-12-10 00:00:00\"\n",
    "# zoom_end_date =   \"2024-12-12 00:00:00\"\n",
    "# plot_touch_detection_areas(touch_detection_areas)\n",
    "# plot_touch_detection_areas(touch_detection_areas, zoom_start_date, zoom_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(touch_detection_areas.long_touch_area) + len(touch_detection_areas.short_touch_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(touch_detection_areas.rsi_overbought)\n",
    "# print(touch_detection_areas.rsi_oversold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import trading_bot.TouchArea\n",
    "import trading_bot.TradingStrategy\n",
    "import trading_bot.TradingStrategyParameters\n",
    "import trading_bot.TouchDetection\n",
    "import trading_bot.TradePosition\n",
    "import trading_bot.TypedBarData\n",
    "import trading_bot.VolumeProfile\n",
    "\n",
    "import importlib\n",
    "importlib.reload(trading_bot.TradingStrategy)\n",
    "importlib.reload(trading_bot.TradingStrategyParameters)\n",
    "importlib.reload(trading_bot.TouchDetection)\n",
    "importlib.reload(trading_bot.TradePosition)\n",
    "importlib.reload(trading_bot.TouchArea)\n",
    "importlib.reload(trading_bot.TypedBarData)\n",
    "importlib.reload(trading_bot.VolumeProfile)\n",
    "\n",
    "from trading_bot.TradingStrategy import StrategyParameters, TouchDetectionAreas, TradingStrategy \n",
    "from trading_bot.TouchDetection import *\n",
    "\n",
    "\n",
    "\n",
    "strategy_params = StrategyParameters(\n",
    "    initial_investment=30_000,\n",
    "    max_investment=30_000,\n",
    "\n",
    "    do_longs=True,\n",
    "    do_shorts=True,\n",
    "    sim_longs=True,\n",
    "    sim_shorts=True,\n",
    "    \n",
    "    use_margin=True,\n",
    "    \n",
    "    assume_marginable_and_etb=True,\n",
    "    \n",
    "    times_buying_power=1,\n",
    "    \n",
    "    soft_start_time = '09:30', \n",
    "    soft_end_time = '15:30',\n",
    "    \n",
    "    # plot_day_results=True,\n",
    "    # plot_volume_profiles=True,\n",
    "    \n",
    "    # allow_reversal_detection=True, # False (no switching) seems better for more stocks. If True, clear_passed_areas=True might improve performance.\n",
    "    \n",
    "    clear_passed_areas=True,\n",
    "\n",
    "    # ### OUTDATED ### False is better for meme stocks, True better for mid and losing stocks (reduces losses). ### OUTDATED ###\n",
    "    \n",
    "    # True is better for meme stocks, False better for mid and losing stocks (reduces losses).\n",
    "    \n",
    "    clear_traded_areas=True,\n",
    "    # True is better/safer for meme/mid?\n",
    "    \n",
    "    \n",
    "    \n",
    "    # min_stop_dist_relative_change_for_partial=1,\n",
    "    \n",
    "    \n",
    "    # volume_profile_ema_span=np.inf,\n",
    "    # volume_profile_ema_span=240,\n",
    "    # volume_profile_ema_span=390,\n",
    "    gradual_entry_range_multiplier = 0.9\n",
    "    \n",
    ")\n",
    "\n",
    "# strategy_params.slippage.slippage_factor=1  # default is 0.02\n",
    "strategy_params.ordersizing.max_volume_percentage = 0.2 # %. default is 1 %\n",
    "# strategy_params.slippage.slippage_factor = 0\n",
    "\n",
    "# export_graph_name = f\"trades_pl_graphs_{symbol.replace('/','-')}_{start_date.split()[0]}_{end_date.split()[0]}\"\n",
    "export_trades_name = f\"trades_output_{symbol.replace('/','-')}_{start_date.split()[0]}_{end_date.split()[0]}\"\n",
    "folder_name = f\"test anchored vwap metrics\"\n",
    "strategy = TradingStrategy(touch_detection_areas, strategy_params, log_level=logging.WARNING, export_trades_path=f'{folder_name}/{export_trades_name}.csv')\n",
    "# strategy = TradingStrategy(touch_detection_areas, strategy_params, export_trades_path=f'trades_output_{symbol.replace('/','-')} get_latest_value 1.725.csv')\n",
    "results = strategy.run_backtest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the metrics to include\n",
    "metrics_to_include = ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "columns_to_exclude = ['ID', 'AreaID', 'date', 'Entry Time', 'Exit Time', 'open', 'high', 'low', 'close', 'Entry Price', 'Exit Price', 'vwap', 'Times Buying Power']\n",
    "\n",
    "# Add non-numeric columns to exclusion list\n",
    "non_numeric_cols = results.select_dtypes(exclude=['float64', 'float32', 'int64', 'int32']).columns\n",
    "columns_to_exclude.extend(non_numeric_cols)\n",
    "columns_to_exclude.remove('Side Win Lose')\n",
    "\n",
    "# Create custom describe function that excludes NaN values in counts\n",
    "def custom_describe(group):\n",
    "    return pd.DataFrame({\n",
    "        col: {\n",
    "            'count': group[col].count(),  # Counts non-NaN values\n",
    "            'mean': group[col].mean(),\n",
    "            'std': group[col].std(),\n",
    "            'min': group[col].min(),\n",
    "            '25%': group[col].quantile(0.25),\n",
    "            '50%': group[col].quantile(0.50),\n",
    "            '75%': group[col].quantile(0.75),\n",
    "            'max': group[col].max()\n",
    "        } for col in group.columns\n",
    "    })\n",
    "\n",
    "# Compute the descriptive statistics and filter\n",
    "custom_describe_df = results.drop(columns=columns_to_exclude, errors='ignore') \\\n",
    "    .groupby('Side Win Lose') \\\n",
    "    .apply(custom_describe)\n",
    "\n",
    "# Filter out metrics not in the desired list\n",
    "filtered_describe = custom_describe_df.loc[custom_describe_df.index.get_level_values(1).isin(metrics_to_include)]\n",
    "filtered_describe = filtered_describe.reset_index().rename(columns={'level_1':'func'})\n",
    "\n",
    "# Split Side Win Lose into separate columns\n",
    "temp = filtered_describe['Side Win Lose']\n",
    "filtered_describe.insert(1, 'Side', temp.str.split().str[0])\n",
    "filtered_describe.insert(2, 'WinLose', temp.str.split().str[1])\n",
    "\n",
    "# Convert WinLose to Categorical with custom order\n",
    "filtered_describe['WinLose'] = pd.Categorical(\n",
    "    filtered_describe['WinLose'], \n",
    "    categories=['Win', 'Lose', 'Unentered'], \n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Sort with categorical column\n",
    "filtered_describe.sort_values(\n",
    "    by=['Side', 'WinLose'], \n",
    "    ascending=[True, True], \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "filtered_describe = filtered_describe.round(2)\n",
    "\n",
    "# Add function to Side Win Lose for Excel freezing\n",
    "filtered_describe['Side Win Lose'] = filtered_describe['Side Win Lose'] + ' ' + filtered_describe['func']\n",
    "\n",
    "# Split into two dataframes based on 'func'\n",
    "stats_df = filtered_describe[filtered_describe['func'] != 'count']\n",
    "counts_df = filtered_describe[filtered_describe['func'] == 'count']\n",
    "\n",
    "# Concatenate with empty row in between\n",
    "final_df = pd.concat([stats_df, pd.DataFrame(columns=filtered_describe.columns, index=[0]), counts_df], ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv(f'{folder_name}/{export_trades_path.replace('trades_output','trades_stats')}.csv', index=False)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def get_original_type(row):\n",
    "    \"\"\"If type starts with *, return the original type (opposite of what follows).\"\"\"\n",
    "    if row['Type'].startswith('*'):\n",
    "        return 'Short' if row['Type'].endswith('Long') else 'Long'\n",
    "    return row['Type']\n",
    "\n",
    "def analyze_trading_performance(df):\n",
    "    \"\"\"\n",
    "    Analyze trading performance with focus on price movement patterns,\n",
    "    holding time characteristics, and area behavior.\n",
    "    \"\"\"\n",
    "    # Add indicator for switched areas and original type\n",
    "    df['Switched'] = df['Type'].str.startswith('*')\n",
    "    df['Original_Type'] = df.apply(get_original_type, axis=1)\n",
    "    \n",
    "    # Calculate efficiency metrics\n",
    "    df['Efficiency_Body'] = df['best_price_diff_body_R'] / df['area_width_R']\n",
    "    df['Efficiency_Wick'] = df['best_price_diff_wick_R'] / df['area_width_R']\n",
    "    df['Max_PL_Time_Ratio_Body'] = df['max_pl_body_time'] / df['holding_time']\n",
    "    df['Max_PL_Time_Ratio_Wick'] = df['max_pl_wick_time'] / df['holding_time']\n",
    "    df['Profitable_Time_Ratio'] = df['profitable_time_pct']\n",
    "    \n",
    "    # Setup plotting\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # 1. Price Movement Analysis\n",
    "    plt.subplot(3, 3, 1)\n",
    "    plot_data = pd.melt(df, \n",
    "                        value_vars=['best_price_diff_body_R', 'best_price_diff_wick_R',\n",
    "                                  'worst_price_diff_body_R', 'worst_price_diff_wick_R'],\n",
    "                        var_name='Metric', value_name='Value')\n",
    "    sns.boxplot(data=plot_data, x='Metric', y='Value')\n",
    "    plt.title('Price Movement Distribution')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 2. Efficiency Analysis\n",
    "    plt.subplot(3, 3, 2)\n",
    "    sns.scatterplot(data=df, x='area_width_R', y='ROE (P/L %)',\n",
    "                    hue='Original_Type', size='Efficiency_Body',\n",
    "                    style='Switched', alpha=0.6)\n",
    "    plt.title('Area Width vs ROE\\n(size = price movement efficiency)')\n",
    "    \n",
    "    # 3. Timing Analysis\n",
    "    plt.subplot(3, 3, 3)\n",
    "    sns.scatterplot(data=df, x='Max_PL_Time_Ratio_Body', y='ROE (P/L %)',\n",
    "                    hue='Original_Type', size='Profitable_Time_Ratio',\n",
    "                    style='Switched', alpha=0.6)\n",
    "    plt.title('Max P&L Timing vs ROE\\n(size = profitable time ratio)')\n",
    "    \n",
    "    # 4. Technical Indicator Analysis\n",
    "    plt.subplot(3, 3, 4)\n",
    "    sns.scatterplot(data=df, x='RSI', y='MFI',\n",
    "                    hue='ROE (P/L %)', size='volume_ratio',\n",
    "                    style='Original_Type', alpha=0.6)\n",
    "    plt.title('RSI vs MFI\\n(color = ROE, size = volume ratio)')\n",
    "    \n",
    "    # 5. Price Pattern Analysis\n",
    "    plt.subplot(3, 3, 5)\n",
    "    sns.scatterplot(data=df, x='doji_ratio', y='wick_ratio',\n",
    "                    hue='ROE (P/L %)', size='ATR_ratio',\n",
    "                    style='Original_Type', alpha=0.6)\n",
    "    plt.title('Doji vs Wick Ratio\\n(color = ROE, size = ATR ratio)')\n",
    "    \n",
    "    # 6. Distribution of Profitability Timing\n",
    "    plt.subplot(3, 3, 6)\n",
    "    sns.histplot(data=df, x='Profitable_Time_Ratio',\n",
    "                 hue='Original_Type', multiple=\"stack\")\n",
    "    plt.title('Distribution of Profitable Time Ratio')\n",
    "    \n",
    "    # Statistical Analysis\n",
    "    print(\"\\n=== Trading Performance Analysis ===\\n\")\n",
    "    \n",
    "    # Overall performance\n",
    "    print(\"Overall Performance:\")\n",
    "    overall_stats = df.groupby(['Original_Type', 'Switched']).agg({\n",
    "        'ROE (P/L %)': ['count', 'mean', 'std', 'min', 'max'],\n",
    "        'holding_time': 'mean',\n",
    "        'Profitable_Time_Ratio': 'mean',\n",
    "        'body_above_buy_price_time': 'mean',\n",
    "    }).round(2)\n",
    "    print(overall_stats)\n",
    "    \n",
    "    # Efficiency analysis\n",
    "    print(\"\\nEfficiency Analysis:\")\n",
    "    efficiency_stats = df.groupby('Original_Type').agg({\n",
    "        'Efficiency_Body': ['mean', 'std'],\n",
    "        'Efficiency_Wick': ['mean', 'std'],\n",
    "        'max_pl_body_time': ['mean', 'std']\n",
    "    }).round(3)\n",
    "    print(efficiency_stats)\n",
    "    \n",
    "    # Area behavior\n",
    "    print(\"\\nArea Behavior:\")\n",
    "    area_stats = df.groupby('Original_Type').agg({\n",
    "        'area_width_R': 'mean',\n",
    "        'body_above_buy_price_time': ['mean', 'std']\n",
    "    }).round(3)\n",
    "    print(area_stats)\n",
    "    \n",
    "    # Correlation with performance\n",
    "    print(\"\\nCorrelations with ROE:\")\n",
    "    perf_indicators = ['best_price_diff_body_R', 'best_price_diff_wick_R',\n",
    "                      'Efficiency_Body', 'Profitable_Time_Ratio',\n",
    "                      'RSI', 'MFI', 'volume_ratio', 'ATR_ratio']\n",
    "    \n",
    "    for indicator in perf_indicators:\n",
    "        coef, p_value = spearmanr(df[indicator], df['ROE (P/L %)'])\n",
    "        print(f\"{indicator:20} coef = {coef:6.3f}, p = {p_value:6.3f}\")\n",
    "    \n",
    "    # Switched vs non-switched effectiveness\n",
    "    print(\"\\nSwitched vs Non-switched Performance:\")\n",
    "    switch_stats = df.groupby(['Original_Type', 'Switched']).agg({\n",
    "        'ROE (P/L %)': ['mean', 'std'],\n",
    "        'Profitable_Time_Ratio': 'mean'\n",
    "    }).round(3)\n",
    "    print(switch_stats)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Example usage:\n",
    "df = pd.read_csv(f'{folder_name}/{export_trades_name}.csv')\n",
    "fig = analyze_trading_performance(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def analyze_macd_confirmation(df):\n",
    "    \"\"\"\n",
    "    Analyze potential MACD-based confirmation signals for trade switching.\n",
    "    \"\"\"\n",
    "    # Create success flag (1 for profitable trades)\n",
    "    df['Success'] = (df['Total P/L'] > 0).astype(int)\n",
    "    \n",
    "    # Create categorical variables for indicator conditions\n",
    "    df['MACD_Direction'] = np.where(df['MACD'] > 0, 'Positive', 'Negative')\n",
    "    df['MACD_Signal_Cross'] = np.where(df['MACD'] > df['MACD_signal'], 'Above', 'Below')\n",
    "    df['MACD_Hist_Direction'] = np.where(df['MACD_hist'] > 0, 'Positive', 'Negative')\n",
    "    df['MACD_Hist_ROC_Direction'] = np.where(df['MACD_hist_roc'] > 0, 'Increasing', 'Decreasing')\n",
    "    \n",
    "    # Separate analyses for overbought and oversold conditions\n",
    "    df['RSI_Condition'] = pd.cut(df['RSI'], \n",
    "                                bins=[0, 30, 70, 100],\n",
    "                                labels=['Oversold', 'Neutral', 'Overbought'])\n",
    "    \n",
    "    # Calculate success rates for different indicator combinations\n",
    "    conditions = ['MACD_Direction', 'MACD_Signal_Cross', 'MACD_Hist_Direction', 'MACD_Hist_ROC_Direction']\n",
    "    \n",
    "    results = []\n",
    "    for condition in conditions:\n",
    "        for rsi_zone in ['Oversold', 'Overbought']:\n",
    "            mask = df['RSI_Condition'] == rsi_zone\n",
    "            success_rates = df[mask].groupby([condition, 'Original_Type'])['Success'].agg(['count', 'mean'])\n",
    "            success_rates = success_rates.round(4)\n",
    "            for idx, row in success_rates.iterrows():\n",
    "                results.append({\n",
    "                    'RSI_Zone': rsi_zone,\n",
    "                    'Condition': condition,\n",
    "                    'Indicator_Value': idx[0],\n",
    "                    'Trade_Type': idx[1],\n",
    "                    'Count': row['count'],\n",
    "                    'Win_Rate': row['mean'] * 100,\n",
    "                    'Avg_ROE': df[mask & (df[condition] == idx[0]) & \n",
    "                                 (df['Original_Type'] == idx[1])]['ROE (P/L %)'].mean() * 100\n",
    "                })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Create combination analysis\n",
    "    def get_indicator_state(row):\n",
    "        return (f\"MACD:{row['MACD_Direction']}, \"\n",
    "                f\"Signal:{row['MACD_Signal_Cross']}, \"\n",
    "                f\"Hist:{row['MACD_Hist_Direction']}, \"\n",
    "                f\"ROC:{row['MACD_Hist_ROC_Direction']}\")\n",
    "    \n",
    "    df['Indicator_State'] = df.apply(get_indicator_state, axis=1)\n",
    "    \n",
    "    # Analyze complex combinations\n",
    "    complex_results = []\n",
    "    for rsi_zone in ['Oversold', 'Overbought']:\n",
    "        mask = df['RSI_Condition'] == rsi_zone\n",
    "        for trade_type in df['Original_Type'].unique():\n",
    "            type_mask = mask & (df['Original_Type'] == trade_type)\n",
    "            states = df[type_mask].groupby('Indicator_State')['Success'].agg(['count', 'mean'])\n",
    "            states = states[states['count'] >= 5]  # Filter for combinations with at least 5 trades\n",
    "            states = states.sort_values('mean', ascending=False)\n",
    "            \n",
    "            for idx, row in states.iterrows():\n",
    "                avg_roe = df[type_mask & (df['Indicator_State'] == idx)]['ROE (P/L %)'].mean() * 100\n",
    "                complex_results.append({\n",
    "                    'RSI_Zone': rsi_zone,\n",
    "                    'Trade_Type': trade_type,\n",
    "                    'Indicator_State': idx,\n",
    "                    'Count': row['count'],\n",
    "                    'Win_Rate': row['mean'] * 100,\n",
    "                    'Avg_ROE': avg_roe\n",
    "                })\n",
    "    \n",
    "    complex_results_df = pd.DataFrame(complex_results)\n",
    "    print(complex_results_df)\n",
    "    \n",
    "    # Decision Tree Analysis\n",
    "    X = df[['MACD', 'MACD_signal', 'MACD_hist', 'MACD_hist_roc', 'RSI', 'RSI_roc','is_res']]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "    \n",
    "    # Separate models for overbought and oversold conditions\n",
    "    for rsi_zone in ['Oversold', 'Overbought']:\n",
    "        mask = df['RSI_Condition'] == rsi_zone\n",
    "        if mask.sum() > 0:  # Only if we have data for this zone\n",
    "            X_zone = X_scaled[mask]\n",
    "            y_zone = df[mask]['Success']\n",
    "            \n",
    "            if len(np.unique(y_zone)) > 1:  # Need at least two classes\n",
    "                dt = DecisionTreeClassifier(max_depth=3, min_samples_leaf=5)\n",
    "                dt.fit(X_zone, y_zone)\n",
    "                \n",
    "                plt.figure(figsize=(15, 10))\n",
    "                plot_tree(dt, feature_names=X.columns, class_names=['Loss', 'Profit'],\n",
    "                         filled=True, rounded=True)\n",
    "                plt.title(f'Decision Tree for {rsi_zone} Conditions')\n",
    "                plt.tight_layout()\n",
    "                \n",
    "    return results_df, complex_results_df\n",
    "\n",
    "# Print analysis insights\n",
    "def print_macd_insights(results_df, complex_results_df):\n",
    "    print(\"=== MACD Confirmation Signal Analysis ===\\n\")\n",
    "    \n",
    "    # Print best individual indicator conditions\n",
    "    for rsi_zone in ['Oversold', 'Overbought']:\n",
    "        print(f\"\\nBest Individual Indicators for {rsi_zone} Conditions:\")\n",
    "        zone_results = results_df[results_df['RSI_Zone'] == rsi_zone]\n",
    "        for condition in zone_results['Condition'].unique():\n",
    "            best_result = zone_results[zone_results['Condition'] == condition].nlargest(1, 'Win_Rate')\n",
    "            print(f\"\\n{condition}:\")\n",
    "            print(f\"Best combination: {best_result['Indicator_Value'].values[0]}\")\n",
    "            print(f\"Win Rate: {best_result['Win_Rate'].values[0]:.1f}%\")\n",
    "            print(f\"Avg ROE: {best_result['Avg_ROE'].values[0]:.2f}%\")\n",
    "            print(f\"Sample Size: {best_result['Count'].values[0]}\")\n",
    "    \n",
    "    # Print best combined conditions\n",
    "    print(\"\\n=== Best Combined Indicator States ===\")\n",
    "    print(complex_results_df)\n",
    "    for rsi_zone in ['Oversold', 'Overbought']:\n",
    "        print(f\"\\nTop 3 Combinations for {rsi_zone} Conditions:\")\n",
    "        zone_results = complex_results_df[complex_results_df['RSI_Zone'] == rsi_zone]\n",
    "        top_results = zone_results.nlargest(3, 'Win_Rate')\n",
    "        for _, row in top_results.iterrows():\n",
    "            print(f\"\\nIndicator State: {row['Indicator_State']}\")\n",
    "            print(f\"Win Rate: {row['Win_Rate']:.1f}%\")\n",
    "            print(f\"Avg ROE: {row['Avg_ROE']:.2f}%\")\n",
    "            print(f\"Sample Size: {row['Count']}\")\n",
    "\n",
    "    print(\"\\n=== Recommendations ===\")\n",
    "    print(\"Consider using these confirmation signals when:\")\n",
    "    \n",
    "    for rsi_zone in ['Oversold', 'Overbought']:\n",
    "        best_combo = complex_results_df[\n",
    "            complex_results_df['RSI_Zone'] == rsi_zone\n",
    "        ].nlargest(1, 'Win_Rate')\n",
    "        \n",
    "        if not best_combo.empty:\n",
    "            print(f\"\\nFor {rsi_zone} conditions:\")\n",
    "            print(f\"- Wait for: {best_combo['Indicator_State'].values[0]}\")\n",
    "            print(f\"- Expected Win Rate: {best_combo['Win_Rate'].values[0]:.1f}%\")\n",
    "            print(f\"- Expected Avg ROE: {best_combo['Avg_ROE'].values[0]:.2f}%\")\n",
    "\n",
    "# Example usage:\n",
    "results_df, complex_results_df = analyze_macd_confirmation(df)\n",
    "print_macd_insights(results_df, complex_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbols = ['AAPL','INTC','JNJ','TSLA','MSFT','AMZN','ABBV']\n",
    "# symbols = ['AAPL', 'MSFT', 'NVDA', 'TSLA', 'AMZN', 'JPM', 'GOOGL', 'META', 'XOM', 'CVX', 'UNH', 'PFE', 'KO', 'PG', 'BA', 'CAT']\n",
    "# symbols = ['NVDA', 'JPM', 'GOOGL', 'META', 'XOM', 'CVX', 'UNH', 'PFE', 'KO', 'PG', 'BA', 'CAT']\n",
    "symbols = ['AAPL', 'MSFT', 'NVDA', 'GOOGL', 'AMZN', 'TSLA', 'JPM', 'BAC', 'META', 'T', 'VZ', 'XOM', 'CVX', 'JNJ', 'PFE', 'KO'] # test 7. generally high-liquidity from 2016 to present\n",
    "# symbols = ['AAPL', 'MSFT', 'NVDA', 'INTC', 'AMZN', 'TSLA', 'DIS', 'JPM', 'BAC', 'GOOGL', 'META', 'XOM', 'CVX', 'JNJ', 'PFE', 'KO'] # test3,7. generally high-liquidity from 2016 to 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades_folder = 'test7/trades'\n",
    "graphs_folder = 'test7/graphs'\n",
    "xbp_folder = 'test7/xbp'\n",
    "\n",
    "from IPython.utils import io\n",
    "for s in symbols:\n",
    "    touch_detection_params.symbol = s\n",
    "    touch_detection_params.export_bars_path=f'bars/bars_{touch_detection_params.symbol}_{start_date.split()[0]}_{end_date.split()[0]}.csv'\n",
    "    \n",
    "    # print(touch_detection_params.symbol)\n",
    "    # print(touch_detection_params.export_bars_path)\n",
    "    results_list = []\n",
    "    \n",
    "    # print(touch_detection_params)\n",
    "    touch_detection_areas = calculate_touch_detection_area(touch_detection_params)\n",
    "    # continue\n",
    "    for i in tqdm(list(np.arange(0.5, 4.01, 0.5))):\n",
    "        \n",
    "        strategy_params.times_buying_power = i\n",
    "        with io.capture_output() as captured:\n",
    "            strategy = TradingStrategy(touch_detection_areas, strategy_params)\n",
    "            \n",
    "            if i == 1:\n",
    "                strategy.export_trades_path=f'{trades_folder}/trades_{touch_detection_params.symbol}_{start_date.split()[0]}_{end_date.split()[0]}.csv'\n",
    "                strategy.export_graph_path=f'{graphs_folder}/{start_date.split()[0]}_{end_date.split()[0]}/graph_{touch_detection_params.symbol}_{start_date.split()[0]}_{end_date.split()[0]}.png'\n",
    "            \n",
    "            balance, longs_executed, shorts_executed, balance_change, mean_plpc, win_mean_plpc, lose_mean_plpc, winrate, total_costs, \\\n",
    "                avg_transact, count_entry_adjust, count_entry_skip, count_exit_adjust, count_exit_skip, key_stats = \\\n",
    "                strategy.run_backtest()\n",
    "\n",
    "        trades_executed = longs_executed + shorts_executed\n",
    "        newrow = {\n",
    "            'xBP': i,\n",
    "            'net%': balance_change,\n",
    "            'balance': balance,\n",
    "            'cnt': trades_executed,\n",
    "            # 'AvgPL%': mean_plpc,\n",
    "            # 'winAvgPL%': win_mean_plpc,\n",
    "            # 'loseAvgPL%': lose_mean_plpc,\n",
    "            'WR%': winrate,\n",
    "            'TotalCosts': total_costs,\n",
    "            # 'avg transactions': avg_transact,\n",
    "            'entryAdjust': count_entry_adjust,\n",
    "            'entrySkip': count_entry_skip,\n",
    "            'exitAdjust': count_exit_adjust,\n",
    "            'exitSkip': count_exit_skip,\n",
    "            **key_stats\n",
    "        }\n",
    "        results_list.append(newrow)\n",
    "\n",
    "    results = pd.DataFrame(results_list)\n",
    "    # Format specific columns if needed\n",
    "    results['xBP'] = results['xBP'].map('{:.1f}'.format)\n",
    "    results['balance'] = results['balance'].map('${:.4f}'.format)\n",
    "    results['TotalCosts'] = results['TotalCosts'].map('${:.4f}'.format)\n",
    "\n",
    "    # Format all float columns\n",
    "    float_columns = results.select_dtypes(include=['float64']).columns\n",
    "    results[float_columns] = results[float_columns].applymap('{:.4f}'.format)\n",
    "\n",
    "    # Display the results\n",
    "    # pd.set_option('display.max_columns', None)\n",
    "    filename = f'{xbp_folder}/xbp_{touch_detection_params.symbol}_{start_date.split()[0]}_{end_date.split()[0]}.csv'\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    results.to_csv(filename,index=False)\n",
    "    # results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbols = ['AAPL', 'MSFT', 'NVDA', 'TSLA', 'AMZN', 'JPM', 'GOOGL', 'META', 'XOM', 'CVX', 'UNH', 'PFE', 'KO', 'PG', 'BA', 'CAT','INTC','JNJ','ABBV'] # test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_combined = pd.DataFrame()\n",
    "for s in symbols:\n",
    "    fname = f'{xbp_folder}/xbp_{s}_{start_date.split()[0]}_{end_date.split()[0]}.csv'\n",
    "    results = pd.read_csv(fname)\n",
    "    results['symbol'] = s\n",
    "    first_column = results.pop('symbol') \n",
    "    results.insert(0, 'symbol', first_column) \n",
    "    results_combined = pd.concat([results_combined, results],ignore_index=True)\n",
    "results_combined['WinMax'] = results_combined[['LwinMax', 'SwinMax']].max(axis=1)\n",
    "results_combined['LoseMin'] = results_combined[['LloseMin', 'SloseMin']].max(axis=1)\n",
    "pd.set_option('display.max_rows', results_combined.shape[0])\n",
    "pd.set_option('display.max_columns', results_combined.shape[1])\n",
    "results_combined.loc[results_combined.xBP.isin({1,4})].sort_values('net%',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in symbols:\n",
    "    fname = f'{xbp_folder}/xbp_{s}_{start_date.split()[0]}_{end_date.split()[0]}.csv'\n",
    "    results = pd.read_csv(fname)\n",
    "    plt.plot(results.xBP.astype(float).to_list(), results.AllAvg.astype(float).to_list(), label=s)\n",
    "plt.legend(bbox_to_anchor=(1.0, 1.0), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in symbols:\n",
    "    fname = f'{xbp_folder}/xbp_{s}_{start_date.split()[0]}_{end_date.split()[0]}.csv'\n",
    "    results = pd.read_csv(fname)\n",
    "    plt.plot(results.xBP.astype(float).to_list(), results['net%'].astype(float).to_list(), label=s)\n",
    "plt.legend(bbox_to_anchor=(1.0, 1.0), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in symbols:\n",
    "    fname = f'{xbp_folder}/xbp_{s}_{start_date.split()[0]}_{end_date.split()[0]}.csv'\n",
    "    results = pd.read_csv(fname)\n",
    "    plt.plot(results.xBP.astype(float).to_list(), results['WR%'].astype(float).to_list(), label=s)\n",
    "plt.legend(bbox_to_anchor=(1.0, 1.0), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from zoneinfo import ZoneInfo\n",
    "ny_tz = ZoneInfo(\"America/New_York\")\n",
    "symbols = ['AAPL', 'MSFT', 'NVDA', 'INTC', 'AMZN', 'TSLA', 'DIS', 'JPM', 'BAC', 'GOOGL', 'META', 'XOM', 'CVX', 'JNJ', 'PFE', 'KO']\n",
    "start_date = \"2017-01-01 00:00:00\"\n",
    "end_date =   \"2018-01-01 00:00:00\"\n",
    "\n",
    "for s in symbols:\n",
    "    fname = f'{trades_folder}/trades_{s}_{start_date.split()[0]}_{end_date.split()[0]}.csv'\n",
    "    trades = csv_to_trade_positions(fname)\n",
    "    \n",
    "    export_bars_path=f'bars/bars_{s}_{start_date.split()[0]}_{end_date.split()[0]}.csv'\n",
    "    zip_file_path = export_bars_path.replace('.csv', '.zip')\n",
    "\n",
    "    csv_file = zipfile.ZipFile(zip_file_path, 'r').open(os.path.basename(export_bars_path))\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True).dt.tz_convert(ny_tz)\n",
    "    df.set_index(['symbol', 'timestamp'], inplace=True)\n",
    "    fill_missing_data(df)\n",
    "    print(f'Retrieved bars from {zip_file_path}')\n",
    "    \n",
    "    # plot_cumulative_pl_and_price(trades, df, None)\n",
    "    \n",
    "    export_graph_path=f'{graphs_folder}/{start_date.split()[0]}_{end_date.split()[0]}/graph_{s}_{start_date.split()[0]}_{end_date.split()[0]}.png'\n",
    "    plot_cumulative_pl_and_price(trades, df, None, filename=export_graph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from zoneinfo import ZoneInfo\n",
    "ny_tz = ZoneInfo(\"America/New_York\")\n",
    "symbols = ['AAPL', 'MSFT', 'NVDA', 'GOOGL', 'AMZN', 'TSLA', 'JPM', 'BAC', 'META', 'T', 'VZ', 'XOM', 'CVX', 'JNJ', 'PFE', 'KO'] \n",
    "start_date = \"2024-01-01 00:00:00\"\n",
    "end_date =   \"2024-09-27 00:00:00\"\n",
    "\n",
    "for s in symbols:\n",
    "    fname = f'{trades_folder}/trades_{s}_{start_date.split()[0]}_{end_date.split()[0]}.csv'\n",
    "    trades = csv_to_trade_positions(fname)\n",
    "    \n",
    "    export_bars_path=f'bars/bars_{s}_{start_date.split()[0]}_{end_date.split()[0]}.csv'\n",
    "    zip_file_path = export_bars_path.replace('.csv', '.zip')\n",
    "\n",
    "    csv_file = zipfile.ZipFile(zip_file_path, 'r').open(os.path.basename(export_bars_path))\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True).dt.tz_convert(ny_tz)\n",
    "    df.set_index(['symbol', 'timestamp'], inplace=True)\n",
    "    fill_missing_data(df)\n",
    "    print(f'Retrieved bars from {zip_file_path}')\n",
    "    \n",
    "    # plot_cumulative_pl_and_price(trades, df, None)\n",
    "    \n",
    "    export_graph_path=f'{graphs_folder}/{start_date.split()[0]}_{end_date.split()[0]}/graph_{s}_{start_date.split()[0]}_{end_date.split()[0]}.png'\n",
    "    plot_cumulative_pl_and_price(trades, df, None, filename=export_graph_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading_bot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
